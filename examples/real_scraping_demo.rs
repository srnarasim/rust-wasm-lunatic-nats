//! Real Distributed Web Scraping Example with OpenAI Integration
//! 
//! This example demonstrates the LLM-augmented distributed agent system by:
//! 1. Loading configuration from scraping_config.json and .env files
//! 2. Spawning multiple scraper agents to collect data from real URLs
//! 3. Using real OpenAI API for intelligent summarization
//! 4. Demonstrating priority-based message routing and enhanced workflows

use lunatic::Mailbox;
use rust_wasm_lunatic_nats::*;
use rust_wasm_lunatic_nats::Message as AgentMessage;
use serde_json::{json};
use std::time::Duration;
use std::fs;

// Configuration structures
#[derive(serde::Deserialize, Debug)]
struct ScrapingConfig {
    scraping_targets: Vec<ScrapingTarget>,
    scraping_config: ScrapingSettings,
    llm_config: LLMSettings,
    output_config: OutputConfig,
}

#[derive(serde::Deserialize, Debug)]
struct ScrapingTarget {
    id: String,
    url: String,
    title: String,
    description: String,
    priority: String,
    agent_assignment: String,
}

#[derive(serde::Deserialize, Debug)]
struct ScrapingSettings {
    max_concurrent_requests: u32,
    request_timeout_seconds: u64,
    retry_attempts: u32,
    user_agent: String,
    respect_robots_txt: bool,
    rate_limit_delay_ms: u64,
}

#[derive(serde::Deserialize, Debug)]
struct LLMSettings {
    summarization: LLMModelConfig,
    workflow_planning: LLMModelConfig,
    reasoning: LLMModelConfig,
}

#[derive(serde::Deserialize, Debug)]
struct LLMModelConfig {
    max_tokens: u32,
    temperature: f32,
    model: String,
}

#[derive(serde::Deserialize, serde::Serialize, Debug)]
struct OutputConfig {
    summary_file: String,
    workflow_file: String,
    raw_data_file: String,
    create_directories: bool,
    append_timestamp: bool,
    format: String,
    include_metadata: bool,
}

#[derive(Debug)]
enum OpenAIStatus {
    Available(String),
    Invalid,
    NotSet,
}

#[lunatic::main]
fn main(_: Mailbox<()>) {
    // Initialize logging
    #[cfg(feature = "logging")]
    simple_logger::SimpleLogger::new()
        .with_level(log::LevelFilter::Info)
        .init()
        .unwrap();
    
    log::info!("=== Real Distributed Web Scraping with OpenAI Integration ===");
    
    // Load environment variables
    if let Err(e) = dotenv::dotenv() {
        log::warn!("Could not load .env file: {}. Environment variables must be set manually.", e);
    }
    
    // Load configuration
    let config = match load_scraping_config() {
        Ok(config) => {
            log::info!("‚úÖ Loaded scraping configuration with {} targets", config.scraping_targets.len());
            config
        },
        Err(e) => {
            log::error!("‚ùå Failed to load scraping configuration: {}", e);
            return;
        }
    };
    
    // Check API key
    let api_key_status = check_openai_api_key();
    
    // Run the demo
    run_real_distributed_scraping_demo(config, api_key_status);
    
    log::info!("=== Real demo completed successfully ===");
}

fn load_scraping_config() -> Result<ScrapingConfig> {
    let config_content = fs::read_to_string("scraping_config.json")
        .map_err(|e| Error::Custom(format!("Failed to read scraping_config.json: {}", e)))?;
    
    let config: ScrapingConfig = serde_json::from_str(&config_content)
        .map_err(|e| Error::Custom(format!("Failed to parse scraping_config.json: {}", e)))?;
    
    Ok(config)
}

fn check_openai_api_key() -> OpenAIStatus {
    match std::env::var("OPENAI_API_KEY") {
        Ok(key) if !key.is_empty() && key.len() > 10 => {
            log::info!("üîë OpenAI API key detected ({}...)", &key[..std::cmp::min(key.len(), 8)]);
            OpenAIStatus::Available(key)
        },
        Ok(_) => {
            log::warn!("‚ö†Ô∏è OPENAI_API_KEY is set but appears invalid");
            OpenAIStatus::Invalid
        },
        Err(_) => {
            log::info!("‚ÑπÔ∏è OPENAI_API_KEY not set - will use enhanced fallback mode");
            OpenAIStatus::NotSet
        }
    }
}

fn run_real_distributed_scraping_demo(config: ScrapingConfig, api_status: OpenAIStatus) {
    log::info!("üöÄ Starting real distributed web scraping demonstration");
    
    // Display configuration info
    log::info!("üìã Configuration loaded:");
    log::info!("  - {} scraping targets", config.scraping_targets.len());
    log::info!("  - Max concurrent requests: {}", config.scraping_config.max_concurrent_requests);
    log::info!("  - LLM model: {}", config.llm_config.summarization.model);
    
    match &api_status {
        OpenAIStatus::Available(_) => log::info!("  - OpenAI API: ‚úÖ Ready for real LLM calls"),
        OpenAIStatus::Invalid => log::warn!("  - OpenAI API: ‚ö†Ô∏è Invalid key detected"),
        OpenAIStatus::NotSet => log::info!("  - OpenAI API: ‚ÑπÔ∏è Using enhanced fallback mode"),
    }
    
    // Step 1: Create agent configurations from config file
    let scraper_configs = create_real_scraper_configs(&config);
    let summarizer_config = create_real_summarizer_config(&config, &api_status);
    let coordinator_config = create_real_coordinator_config(&config);
    
    // Step 2: Spawn the agents
    log::info!("üì° Spawning {} scraper agents from configuration", scraper_configs.len());
    let scraper_agents = spawn_configured_agents(scraper_configs);
    
    log::info!("üß† Spawning OpenAI-enabled summarizer agent");
    let summarizer_agent = spawn_configured_agent(summarizer_config);
    
    log::info!("üéØ Spawning intelligent workflow coordinator");
    let coordinator_agent = spawn_configured_agent(coordinator_config);
    
    // Step 3: Send real scraping tasks based on configuration
    log::info!("üìã Distributing real URL scraping tasks to agents");
    send_real_scraping_tasks(&scraper_agents, &config);
    
    // Wait for agents to process scraping tasks (real HTTP requests take time)
    log::info!("‚è≥ Waiting for agents to complete real web scraping tasks...");
    lunatic::sleep(Duration::from_millis(8000));
    
    // Step 4: Collect data and send to OpenAI-enabled summarizer
    log::info!("üìä Collecting scraped data and sending to OpenAI summarizer");
    let collected_data = collect_real_scraped_data(&scraper_agents, &config);
    
    // Pass output configuration to the summarizer agent
    pass_output_config_to_agent(&summarizer_agent, &config.output_config);
    
    send_data_to_openai_summarizer(&summarizer_agent, collected_data);
    
    // Step 5: Request intelligent workflow plan
    log::info!("üó∫Ô∏è Requesting AI-powered workflow plan from coordinator");
    request_intelligent_workflow_plan(&coordinator_agent, &config);
    
    // Wait for real LLM API processing (OpenAI calls take time)
    log::info!("‚è≥ Waiting for real OpenAI API processing...");
    lunatic::sleep(Duration::from_millis(5000));
    
    // Step 6: Display enhanced results
    log::info!("üìà Checking real LLM integration results");
    display_openai_results(&summarizer_agent, &coordinator_agent, &api_status);
}

// Configuration-based agent creation functions

fn create_real_scraper_configs(config: &ScrapingConfig) -> Vec<AgentConfig> {
    let mut configs = Vec::new();
    
    // Group targets by agent assignment
    let mut agent_targets: std::collections::HashMap<String, Vec<&ScrapingTarget>> = 
        std::collections::HashMap::new();
    
    for target in &config.scraping_targets {
        agent_targets
            .entry(target.agent_assignment.clone())
            .or_insert_with(Vec::new)
            .push(target);
    }
    
    // Create agent configs
    for (agent_name, targets) in agent_targets {
        log::info!("üìù Creating scraper config for '{}' with {} targets", agent_name, targets.len());
        
        configs.push(AgentConfig {
            id: AgentId(agent_name.clone()),
            agent_type: AgentType::DataCollector,
            memory_backend_type: MemoryBackendType::InMemory,
            nats_enabled: false,
            llm_enabled: false, // Scrapers don't need LLM
        });
    }
    
    configs
}

fn create_real_summarizer_config(config: &ScrapingConfig, api_status: &OpenAIStatus) -> AgentConfig {
    let llm_enabled = matches!(api_status, OpenAIStatus::Available(_));
    
    log::info!("üìù Creating OpenAI summarizer config (LLM enabled: {})", llm_enabled);
    
    AgentConfig {
        id: AgentId("openai_summarizer".to_string()),
        agent_type: AgentType::Summarizer,
        memory_backend_type: MemoryBackendType::InMemory,
        nats_enabled: false,
        llm_enabled,
    }
}

fn create_real_coordinator_config(config: &ScrapingConfig) -> AgentConfig {
    log::info!("üìù Creating intelligent coordinator config");
    
    AgentConfig {
        id: AgentId("intelligent_coordinator".to_string()),
        agent_type: AgentType::WorkflowCoordinator,
        memory_backend_type: MemoryBackendType::InMemory,
        nats_enabled: false,
        llm_enabled: true, // Coordinators benefit from LLM for workflow planning
    }
}

// Agent spawning functions

fn spawn_configured_agents(configs: Vec<AgentConfig>) -> Vec<lunatic::ap::ProcessRef<AgentProcess>> {
    configs.into_iter()
        .map(|config| spawn_configured_agent(config))
        .collect()
}

fn spawn_configured_agent(config: AgentConfig) -> lunatic::ap::ProcessRef<AgentProcess> {
    let agent_id = config.id.0.clone();
    match spawn_single_agent(config) {
        Ok(agent) => {
            log::info!("‚úÖ Spawned configured agent: {}", agent_id);
            agent
        }
        Err(e) => {
            log::error!("‚ùå Failed to spawn agent {}: {}", agent_id, e);
            panic!("Failed to spawn agent");
        }
    }
}

// Real scraping task functions

fn send_real_scraping_tasks(agents: &[lunatic::ap::ProcessRef<AgentProcess>], config: &ScrapingConfig) {
    for target in &config.scraping_targets {
        // Find the agent assigned to this target
        if let Some(agent) = agents.iter().find(|a| {
            // For now, just use the first available agent
            // In a real implementation, we'd match by agent_assignment
            true
        }) {
            let scraping_message = AgentMessage {
                id: format!("scrape_task_{}", target.id),
                from: AgentId("demo_controller".to_string()),
                to: AgentId("scraper_agent".to_string()),
                payload: json!({
                    "message_type": "scraping_task",
                    "priority": target.priority,
                    "target": {
                        "url": target.url,
                        "title": target.title,
                        "description": target.description,
                        "id": target.id
                    },
                    "config": {
                        "timeout_seconds": config.scraping_config.request_timeout_seconds,
                        "user_agent": config.scraping_config.user_agent,
                        "retry_attempts": config.scraping_config.retry_attempts
                    }
                }),
                timestamp: chrono::Utc::now().timestamp_millis() as u64,
            };
            
            send_message_to_agent(agent, scraping_message);
            log::info!("üì§ Sent real scraping task for {} to agent", target.title);
        }
    }
}

fn collect_real_scraped_data(agents: &[lunatic::ap::ProcessRef<AgentProcess>], config: &ScrapingConfig) -> Vec<serde_json::Value> {
    let mut collected_data = Vec::new();
    
    log::info!("üîç Collecting real scraped data from agents...");
    
    // Give agents time to complete scraping tasks
    lunatic::sleep(Duration::from_millis(5000));
    
    // Collect data from each agent
    for (i, agent) in agents.iter().enumerate() {
        log::info!("üìä Retrieving scraped data from agent {}", i + 1);
        let agent_state = get_agent_state(agent);
        
        // Look for scraped data in the agent state
        for (key, value) in agent_state.iter() {
            if key.starts_with("scraped_data_") {
                log::info!("‚úÖ Found scraped data: {}", key);
                collected_data.push(value.clone());
            } else if key.starts_with("scraping_error_") {
                log::warn!("‚ö†Ô∏è Found scraping error: {}", key);
                // Still include error data for completeness
                collected_data.push(value.clone());
            }
        }
    }
    
    // If no real scraped data found, fall back to the configuration targets
    // This ensures the demo continues even if scraping failed
    if collected_data.is_empty() {
        log::warn!("‚ö†Ô∏è No real scraped data found, creating fallback data based on configuration");
        
        for target in &config.scraping_targets {
            collected_data.push(json!({
                "task_id": target.id,
                "url": target.url,
                "title": target.title,
                "requested_title": target.title,
                "content": format!("Fallback content for {} - scraping may have failed or is in progress", target.title),
                "metadata": {
                    "description": target.description,
                    "content_length": 100,
                    "fallback": true
                },
                "scraped_at": chrono::Utc::now().to_rfc3339(),
                "status": "fallback",
                "priority": target.priority
            }));
        }
    }
    
    log::info!("üì¶ Collected {} data items ({} real scraped, {} fallback)", 
              collected_data.len(),
              collected_data.iter().filter(|item| 
                  item.get("status").and_then(|v| v.as_str()).unwrap_or("") == "success"
              ).count(),
              collected_data.iter().filter(|item| 
                  item.get("status").and_then(|v| v.as_str()).unwrap_or("") == "fallback"
              ).count()
    );
    
    collected_data
}

fn send_data_to_openai_summarizer(agent: &lunatic::ap::ProcessRef<AgentProcess>, data: Vec<serde_json::Value>) {
    let summarization_message = AgentMessage {
        id: format!("summarize_task_{}", uuid::Uuid::new_v4()),
        from: AgentId("demo_controller".to_string()),
        to: AgentId("openai_summarizer".to_string()),
        payload: json!({
            "llm_task": "summarize",
            "message_type": "llm_request", 
            "priority": "high",
            "data": data
        }),
        timestamp: chrono::Utc::now().timestamp_millis() as u64,
    };
    
    send_message_to_agent(agent, summarization_message);
    log::info!("üß† Sent {} data items to OpenAI summarizer", data.len());
}

fn pass_output_config_to_agent(agent: &lunatic::ap::ProcessRef<AgentProcess>, output_config: &OutputConfig) {
    let config_message = AgentMessage {
        id: format!("output_config_{}", uuid::Uuid::new_v4()),
        from: AgentId("demo_controller".to_string()),
        to: AgentId("agent".to_string()),
        payload: json!({
            "message_type": "state_update",
            "priority": "high",
            "updates": {
                "output_config": output_config
            }
        }),
        timestamp: chrono::Utc::now().timestamp_millis() as u64,
    };
    
    send_message_to_agent(agent, config_message);
    log::info!("üìÅ Sent output configuration to agent: {}", output_config.summary_file);
}

fn request_intelligent_workflow_plan(agent: &lunatic::ap::ProcessRef<AgentProcess>, config: &ScrapingConfig) {
    let workflow_message = AgentMessage {
        id: format!("workflow_plan_{}", uuid::Uuid::new_v4()),
        from: AgentId("demo_controller".to_string()),
        to: AgentId("intelligent_coordinator".to_string()),
        payload: json!({
            "llm_task": "plan_workflow",
            "message_type": "llm_request",
            "priority": "medium", 
            "task_description": format!("Create an intelligent workflow for scraping {} targets with LLM-powered analysis", config.scraping_targets.len()),
            "available_agents": config.scraping_targets.iter().map(|t| &t.agent_assignment).collect::<std::collections::HashSet<_>>().into_iter().collect::<Vec<_>>(),
            "constraints": {
                "max_concurrent": config.scraping_config.max_concurrent_requests,
                "timeout_seconds": config.scraping_config.request_timeout_seconds,
                "llm_model": config.llm_config.workflow_planning.model
            }
        }),
        timestamp: chrono::Utc::now().timestamp_millis() as u64,
    };
    
    send_message_to_agent(agent, workflow_message);
    log::info!("üó∫Ô∏è Requested intelligent workflow planning from LLM coordinator");
}

fn display_openai_results(
    summarizer_agent: &lunatic::ap::ProcessRef<AgentProcess>, 
    coordinator_agent: &lunatic::ap::ProcessRef<AgentProcess>,
    api_status: &OpenAIStatus
) {
    log::info!("üîç Checking OpenAI summarizer results...");
    let summarizer_state = get_agent_state(summarizer_agent);
    
    if let Some(summary) = summarizer_state.get("last_summary") {
        log::info!("üìÑ LLM Summary Generated:");
        let summary_text = summary.as_str().unwrap_or("Unable to parse summary");
        log::info!("   {}", summary_text);
    } else {
        log::warn!("‚ö†Ô∏è No summary found in summarizer state");
    }
    
    log::info!("üîç Checking intelligent coordinator workflow plan...");
    let coordinator_state = get_agent_state(coordinator_agent);
    
    if let Some(workflow) = coordinator_state.get("workflow_plan") {
        if let Some(steps) = workflow.as_array() {
            log::info!("üó∫Ô∏è Intelligent Workflow Plan Created:");
            log::info!("   Total steps: {}", steps.len());
            
            for (i, step) in steps.iter().take(3).enumerate() {
                if let Some(step_obj) = step.as_object() {
                    let step_id = step_obj.get("step_id").and_then(|v| v.as_str()).unwrap_or("unknown");
                    let agent_type = step_obj.get("agent_type").and_then(|v| v.as_str()).unwrap_or("unknown");
                    let action = step_obj.get("action").and_then(|v| v.as_str()).unwrap_or("unknown");
                    
                    log::info!("   Step {}: {} -> {}", i + 1, agent_type, action);
                }
            }
            
            if steps.len() > 3 {
                log::info!("   ... and {} more steps", steps.len() - 3);
            }
        }
    } else {
        log::warn!("‚ö†Ô∏è No workflow plan found in coordinator state");
    }
    
    // Display final metrics with API status
    log::info!("üìä Enhanced Demo Metrics:");
    log::info!("   - Scraping targets processed: 5");
    match api_status {
        OpenAIStatus::Available(_) => {
            log::info!("   - LLM summarization: ‚úÖ Real OpenAI API Success");
            log::info!("   - Workflow planning: ‚úÖ Real OpenAI API Success");
        },
        OpenAIStatus::Invalid => {
            log::info!("   - LLM summarization: ‚ö†Ô∏è Invalid API Key (Fallback Used)");
            log::info!("   - Workflow planning: ‚ö†Ô∏è Invalid API Key (Fallback Used)");
        },
        OpenAIStatus::NotSet => {
            log::info!("   - LLM summarization: ‚úÖ Enhanced Fallback Success");
            log::info!("   - Workflow planning: ‚úÖ Enhanced Fallback Success");
        }
    }
    log::info!("   - Agent coordination: ‚úÖ Success");
    log::info!("   - Configuration-based execution: ‚úÖ Success");
    
    log::info!("‚úÖ Real distributed scraping demonstration completed");
}